//
//    MIT License
//
//    Copyright (c) 2021 Philipp Matthes
//
//    Permission is hereby granted, free of charge, to any person obtaining a copy
//    of this software and associated documentation files (the "Software"), to deal
//    in the Software without restriction, including without limitation the rights
//    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
//    copies of the Software, and to permit persons to whom the Software is
//    furnished to do so, subject to the following conditions:
//
//    The above copyright notice and this permission notice shall be included in all
//    copies or substantial portions of the Software.
//
//    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
//    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
//    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
//    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
//    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
//    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
//    SOFTWARE.

import Foundation
import CoreImage
import CoreML

/// Utility class that encapsulates image segmentation and generation of the mask.
final class NeuralGreenscreen {
    /// The pixel dimensions of the webcam stream.
    private static let webcamSize: CGSize = .init(width: 1280, height: 720)

    /// The pixel dimensions of the segmentation mask generated by the `DeepLab` model.
    private static let segmentationSize: CGSize = .init(width: 513, height: 513)

    /// A flag that is set during inference process, to ensure that only one inference is run at a time.
    private var isBusy = false

    /// The segmentation model used to generate a segmentation of the webcam input pixels.
    private let model: DeepLabV3Int8LUT

    /// A `CIContext` used to render `CIImage`s into `CVPixelBuffer`s.
    private let context = CIContext()

    /// The Metal device used to render the segmentation mask.
    private let device: MTLDevice

    /// The Metal command queue used to render the segmentation mask.
    private let commandQueue: MTLCommandQueue

    /// The Metal compute pipeline state used to render the segmentation mask.
    private let computePipelineState: MTLComputePipelineState

    /// The Metal output texture used to render the segmentation mask.
    private let outputTexture: MTLTexture

    /// Create a new `NeuralGreenscreen` object.
    init() {
        let modelConfig = MLModelConfiguration()
        // Use CPU only, GPU usage leads to stuttering in other apps
        // caused by blocking of their GPU usage
        modelConfig.computeUnits = .cpuOnly
        // The bundle that contains our Metal shaders
        let bundle = Bundle(for: Self.self)

        let outputTextureDescriptor = MTLTextureDescriptor.texture2DDescriptor(
            pixelFormat: .bgra8Unorm,
            width: Int(Self.webcamSize.width),
            height: Int(Self.webcamSize.height),
            mipmapped: false
        )
        outputTextureDescriptor.usage = [.shaderWrite]

        guard
            let model = try? DeepLabV3Int8LUT(configuration: modelConfig),
            let device = MTLCreateSystemDefaultDevice(),
            let commandQueue = device.makeCommandQueue(),
            let library = try? device.makeDefaultLibrary(bundle: bundle),
            let function = library.makeFunction(name: "mask"),
            let computePipelineState = try? device
                .makeComputePipelineState(function: function),
            let outputTexture = device.makeTexture(descriptor: outputTextureDescriptor)
        else { fatalError("Neural Greenscreen initialization failed") }

        self.model = model
        self.device = device
        self.commandQueue = commandQueue
        self.computePipelineState = computePipelineState
        self.outputTexture = outputTexture
    }

    /// Create a new `CVPixelBuffer` for image processing, with a given size.
    private func createPixelBuffer(size: CGSize) -> CVPixelBuffer {
        var pixelBuffer: CVPixelBuffer?
        let attrs = [
            kCVPixelBufferCGImageCompatibilityKey: kCFBooleanTrue,
            kCVPixelBufferCGBitmapContextCompatibilityKey: kCFBooleanTrue
        ] as CFDictionary
        CVPixelBufferCreate(
            kCFAllocatorDefault,
            Int(size.width),
            Int(size.height),
            kCVPixelFormatType_32BGRA,
            attrs,
            &pixelBuffer
        )
        guard
            let pixelBuffer = pixelBuffer
        else { fatalError("Could not create new input pixel buffer") }
        return pixelBuffer
    }

    /// Transform the webcam `CVPixelBuffer` into a `CVPixelBuffer` that can be used
    /// as a model input for the `DeepLab` model. The input must have the dimensions `513 x 513`.
    private func createModelInput(_ cameraPixelBuffer: CVPixelBuffer) -> CVPixelBuffer {
        let unresizedRawInput = CIImage(cvPixelBuffer: cameraPixelBuffer)
        let transform = CGAffineTransform(
            scaleX: Self.segmentationSize.width / Self.webcamSize.width,
            y: Self.segmentationSize.height / Self.webcamSize.height
        )
        let resizedRawInput = unresizedRawInput.transformed(by: transform)
        let inputPixelBuffer = createPixelBuffer(size: Self.segmentationSize)
        context.render(resizedRawInput, to: inputPixelBuffer)
        return inputPixelBuffer
    }

    /// Create a buffer that contains the generated segmentation mask and can be
    /// passed to the Metal shader to render a texture.
    private func createMaskBuffer(modelOutput: DeepLabV3Int8LUTOutput) -> (MTLBuffer) {
        let segmentationMap = modelOutput.semanticPredictions
        let bufferLength = Int(Self.segmentationSize.width)
            * Int(Self.segmentationSize.height)
            * MemoryLayout<Int32>.stride
        guard
            let segmentationMaskBuffer = device.makeBuffer(length: bufferLength)
        else { fatalError("Failed to create mask buffer") }

        memcpy(
            segmentationMaskBuffer.contents(),
            segmentationMap.dataPointer,
            segmentationMaskBuffer.length
        )
        return segmentationMaskBuffer
    }

    /// Render an output Metal texture into a new `CVPixelBuffer`.
    private func renderTexture(outputTexture: MTLTexture) -> CVPixelBuffer {
        let kciOptions: [CIImageOption: Any] = [
            .colorSpace: CGColorSpaceCreateDeviceRGB()
        ]
        guard
            let maskImage = CIImage(mtlTexture: outputTexture, options: kciOptions)?
                .oriented(.downMirrored)
        else { fatalError("Failed to render output texture") }
        let outputPixelBuffer = createPixelBuffer(size: Self.webcamSize)
        context.render(maskImage, to: outputPixelBuffer)
        return outputPixelBuffer
    }

    /// Dispatch the thread groups of a Metal command encoder to initiate texture rendering.
    private func dispatchThreadGroups(
        size: CGSize, commandEncoder: MTLComputeCommandEncoder
    ) {
        let counts = MTLSizeMake(16, 16, 1) // Should be ok for any gpu
        let groups = MTLSize(
            width: (Int(size.width) + counts.width - 1) / counts.width,
            height: (Int(size.height) + counts.height - 1) / counts.height,
            depth: 1
        )
        commandEncoder.dispatchThreadgroups(groups, threadsPerThreadgroup: counts)
    }

    /// Create a person mask for the given webcam input pixels.
    /// Calling this function will result in `nil` if the object is busy processing another image.
    func mask(webcamPixelBuffer: CVPixelBuffer) throws -> CVPixelBuffer? {
        guard !isBusy else { return nil }
        isBusy = true

        let modelInput = createModelInput(webcamPixelBuffer)
        let modelOutput = try model.prediction(input: .init(image: modelInput))
        let maskBuffer = createMaskBuffer(modelOutput: modelOutput)

        guard
            let commandBuffer = commandQueue.makeCommandBuffer(),
            let commandEncoder = commandBuffer.makeComputeCommandEncoder()
        else { fatalError("Failed to create Metal command buffer or encoder") }

        commandEncoder.setComputePipelineState(computePipelineState)
        commandEncoder.setTexture(outputTexture, index: 0)
        commandEncoder.setBuffer(maskBuffer, offset: 0, index: 0)
        dispatchThreadGroups(size: Self.webcamSize, commandEncoder: commandEncoder)
        commandEncoder.endEncoding()
        commandBuffer.commit()

        let renderedBuffer = renderTexture(outputTexture: outputTexture)
        isBusy = false

        return renderedBuffer
    }
}


